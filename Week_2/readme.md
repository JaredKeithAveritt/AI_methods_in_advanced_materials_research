

# Introduction to Machine Learning

The following examples introduce concepts that will be very important to modern AI training workflows, but can also be used in some methods you may already be familiar with.

0. [Building a Dataset (optional)](00_make_slimmed_dataset.ipynb)
1. [Fitting a line with Stochastic Gradient Descent](01_linear_regression_sgd.ipynb)
2. [k-means: Another learning method for clustering data](02_clustering.ipynb)

---

Stochastic gradient descent is an iterative learning algorithm that uses a training dataset to update a model.
The batch size is a hyperparameter of gradient descent that controls the number of training samples to work through before the modelâ€™s internal parameters are updated.
The number of epochs is a hyperparameter of gradient descent that controls the number of complete passes through the training dataset.


---
papers of interest: https://doi.org/10.1002/adts.201900145
data sets of interest: https://github.com/NinadBhat/supervised-learning-code
Optional Lecture (on Pandas Dataframes and Tensors): [HERE](./Data_frames_and_Tensors.md)
