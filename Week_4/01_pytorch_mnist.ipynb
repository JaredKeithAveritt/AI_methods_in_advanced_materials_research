{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "# Introduction to Neural Networks \n",
    "Last week we trained a multi-layer perceptron model (a basic kind of neural network) to classify handwritten digits by hand.\n",
    "\n",
    "In this notebook, we will use existing Python libraries to solve a supervised learning problem, specifically a classification problem using the MNIST dataset. \n",
    "\n",
    "We will also furthur our knowledge of neural networks and deep learning through this hands-on example.\n",
    "\n",
    "In particular, we will discuss how to train and improve the  learning capabilities.  We will be using the PyTorch Python library.\n",
    "\n",
    "The [MNIST dataset](http://yann.lecun.com/exdb/mnist/) contains thousands of examples of handwritten numbers, with each digit labeled 0-9.\n",
    "<img src=\"images/mnist_task.png\"  align=\"left\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Statements Explained\n",
    "\n",
    "- `import torch`:  \n",
    "  This imports the PyTorch library into your Python script, making all the functions and classes of PyTorch available. PyTorch is a popular open-source machine learning library for Python, known for its flexibility and dynamic computational graph, which facilitates the development and training of deep learning models.\n",
    "\n",
    "- `import torchvision`:  \n",
    "  Imports the torchvision package, which is a part of the PyTorch project. `torchvision` consists of popular datasets, model architectures, and common image transformations for computer vision. It is particularly useful for loading and preprocessing image data.\n",
    "\n",
    "- `from torch import nn`:  \n",
    "  This line specifically imports the `nn` module from PyTorch. The `nn` module contains classes and functions to build neural networks. It includes layers, activation functions, and utilities for constructing, training, and running neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#This is a magic command (can only use 1 per code block, and must be the first line) for Jupyter notebooks and IPython environments. It ensures that the output of plotting commands is displayed inline within frontends like the Jupyter notebook, directly below the code cell that produced it. The plots will be stored in the notebook document.\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "\n",
    "import numpy \n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The MNIST dataset\n",
    "\n",
    "We will now download the dataset that contains handwritten digits. MNIST is a popular dataset, so we can download it via the PyTorch library. Note:\n",
    "- x is for the inputs (images of handwritten digits) and y is for the labels or outputs (digits 0-9)\n",
    "- We are given \"training\" and \"test\" datasets. Training datasets are used to fit the model. Test datasets are saved until the end, when we are satisfied with our model, to estimate how well our model generalizes to new data.\n",
    "\n",
    "Note that downloading it the first time might take some time.\n",
    "The data is split as follows:\n",
    "- 60,000 training examples, 10,000 test examples\n",
    "- inputs: 1 x 28 x 28 pixels\n",
    "- outputs (labels): one integer per example "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Dataset Loading and Preprocessing\n",
    "\n",
    "The following code snippet is designed to load and preprocess the MNIST dataset. This process prepares the data for training and testing, specifically for image classification tasks. The torchvision library, which is part of the PyTorch ecosystem, provides convenient access to the MNIST dataset along with preprocessing utilities.\n",
    "\n",
    "### Key Parameters:\n",
    "\n",
    "- `root`: Specifies the directory where the dataset will be stored. If the dataset is not already present in this directory, it will be downloaded.\n",
    "- `train=True`: Indicates that we are fetching the training portion of the dataset.\n",
    "- `download=True`: Allows the dataset to be downloaded if it's not already available locally.\n",
    "- `transform=torchvision.transforms.ToTensor()`: Converts a PIL Image or a NumPy ndarray into a FloatTensor and scales the image's pixel intensity values in the range [0., 1.] for model training as PyTorch models operate on tensors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:00<00:00, 28751922.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 41699034.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1648877/1648877 [00:00<00:00, 14673638.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 49481892.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load and transform the training data\n",
    "training_data = torchvision.datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "\n",
    "# Load and transform the test data\n",
    "# Similar to the training data loader but with 'train=False' to specify that we want to\n",
    "# load the test (or validation) portion of the MNIST dataset. This data is used to evaluate\n",
    "# the model's performance on unseen data, providing an estimate of its generalization ability.\n",
    "test_data = torchvision.datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting Explained\n",
    "\n",
    "In machine learning projects, it's crucial to split your dataset into training and validation (or test) sets. This separation allows the model to learn from one subset of the data (training set) and then be evaluated on a separate subset (validation set) to check for overfitting, underfitting, and to generally assess the model's performance on unseen data.\n",
    "\n",
    "The following code snippet performs this splitting operation for a dataset, specifically using PyTorch's utilities. Let's break down the functionality and the purpose of each component in the code.\n",
    "\n",
    "### Understanding the Code\n",
    "\n",
    "We are using the `torch.utils.data.random_split` function to divide a dataset into non-overlapping new datasets of given lengths. Specifically, it splits the `training_data` into two parts: a larger portion for training and a smaller portion for validation. Additionally, it employs a random generator with a fixed seed for reproducibility of results.\n",
    "\n",
    "- `training_data, validation_data` are the new datasets obtained after splitting.\n",
    "- `torch.utils.data.random_split` is the function used for splitting the dataset.\n",
    "- `training_data` is the original dataset that we intend to split.\n",
    "- `[0.8, 0.2]` represents the proportions of the split. However, since `random_split` expects absolute numbers rather than proportions, these values should be calculated based on the actual size of `training_data`.\n",
    "- `generator=torch.Generator().manual_seed(55)` ensures that the random splitting of the dataset is reproducible. The seed `55` is used to initialize the random generator to a fixed state. You can choose any integer (also note that its not really random if its repeatable). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_size = len(training_data)  # Total size of the dataset\n",
    "\n",
    "# Calculate split sizes\n",
    "train_size = int(total_size * 0.8)  # 80% of the dataset for training\n",
    "validation_size = total_size - train_size  # Remaining 20% for validation\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "training_data, validation_data = torch.utils.data.random_split(\n",
    "    training_data, [train_size, validation_size],\n",
    "    generator=torch.Generator().manual_seed(55)  # Ensure reproducibility\n",
    ")\n",
    "\n",
    "# 'training_data' now contains the training subset,\n",
    "# 'validation_data' contains the validation subset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Structure of our Datasets Current status\n",
    "\n",
    "The code consists of two print statements designed to output information about the MNIST dataset that has been split into training, validation, and test sets. Additionally, it prints the shape of the input data.\n",
    "\n",
    "1. **Dataset Size Information**:\n",
    "- The first print statement displays the number of examples in the training, validation, and test datasets. This is crucial for understanding the distribution of data and ensuring there's enough data for training and validation/testing.\n",
    "        \n",
    "2. **Input Shape Information**:\n",
    "- The second print statement reveals the shape of the input data by accessing the first example of the training dataset. This information is vital for configuring the input layer of your neural network and understanding the data's dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST data loaded: train: 30720 examples, validation: 7680 examples, test: 10000 examples\n",
      "Input shape: torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# Print the size of training, validation, and test datasets\n",
    "print('MNIST data loaded: train:', len(training_data), 'examples,',\n",
    "      'validation:', len(validation_data), 'examples,',\n",
    "      'test:', len(test_data), 'examples')\n",
    "\n",
    "# Print the shape of the input data by accessing the first example in the training dataset\n",
    "# Note: training_data[0][0] accesses the first image tensor, and .shape retrieves its dimensions\n",
    "print('Input shape:', training_data[0][0].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing MNIST Digits\n",
    "\n",
    "Here we inspect the first ten images of the MNIST dataset, showcasing the handwritten digits and their corresponding labels. In machine learning, especially in tasks involving images, visualizing your data is crucial for understanding the nature of the dataset you're working with. This visualization can help in examining the data's quality, understanding the variation within classes, and verifying the preprocessing steps. \n",
    "\n",
    "### Code Explanation\n",
    "\n",
    "The code aims to plot the first ten images from the `training_data` of the MNIST dataset, along with their corresponding labels (classes). Here's a breakdown of what each part does:\n",
    "\n",
    "1. **Setting Plot Size**:\n",
    "   - `pltsize=1`: This variable controls the overall figure size ratio.\n",
    "   \n",
    "2. **Creating Figure**:\n",
    "   - `plt.figure(figsize=(10*pltsize, pltsize))`: Initializes a new figure with a specific size. The figure's width is 10 times the `pltsize`, and its height is equal to `pltsize`, aiming to create a row of images. The use of `pltsize` here affects the overall figure size but not individual images directly.\n",
    "\n",
    "3. **Looping Through Images**:\n",
    "   - The loop `for i in range(10):` iterates through the first ten items in the `training_data`.\n",
    "   \n",
    "4. **Plotting Each Image**:\n",
    "   - Within the loop, `plt.subplot(1, 10, i+1)` creates a subplot for each image in a 1x10 grid.\n",
    "   - `plt.axis('off')` removes the axis for clarity.\n",
    "   - `plt.imshow(numpy.reshape(training_data[i][0], (28, 28)), cmap=\"gray\")` displays an image. The [`numpy.reshape` function](https://numpy.org/doc/stable/reference/generated/numpy.reshape.html) changes the shape of the image data to 28x28 pixels, and `cmap=\"gray\"` sets the colormap to grayscale.\n",
    "   - `plt.title('Class: '+str(training_data[i][1]))`: Adds a title to each subplot indicating the class of the digit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x100 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "\n",
    "pltsize = 1\n",
    "# Initialize figure with dimensions proportional to the number of images\n",
    "plt.figure(figsize=(10*pltsize, pltsize))\n",
    "\n",
    "# Display the first 10 images from the training dataset\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)  # Prepare subplot for the ith image\n",
    "    plt.axis('off')  # Hide the axis for a cleaner look\n",
    "    # Display the image, reshaping it to 28x28 pixels, in grayscale\n",
    "    plt.imshow(numpy.reshape(training_data[i][0], (28, 28)), cmap=\"gray\")\n",
    "    # Add a title with the class of the digit\n",
    "    plt.title('Class: '+str(training_data[i][1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Define the batch size for loading the data\n",
    "batch_size = 128\n",
    "\n",
    "# Initialize a DataLoader for the training dataset\n",
    "# This allows iterating over the dataset in batches of 128 samples, facilitating efficient training\n",
    "train_dataloader = torch.utils.data.DataLoader(training_data, batch_size=batch_size)\n",
    "\n",
    "# Similarly, initialize a DataLoader for the validation dataset\n",
    "# This enables efficient evaluation of the model on the validation set, also in batches of 128 samples\n",
    "val_dataloader = torch.utils.data.DataLoader(validation_data, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalities:\n",
    "To train our classifier, we need (besides the data):\n",
    "- A model that depend on parameters $\\mathbf{\\theta}$. Here we are going to use neural networks.\n",
    "- A loss function $J(\\mathbf{\\theta})$ to measure the capabilities of the model.\n",
    "- An optimization method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Model\n",
    "Let's begin with a simple linear model: linear regression, like last week. \n",
    "We add one complication: each example is a vector (flattened image), so the \"slope\" multiplication becomes a dot product. If the target output is a vector as well, then the multiplication becomes matrix multiplication. \n",
    "\n",
    "Note, like before, we consider multiple examples at once, adding another dimension to the input. \n",
    "\n",
    "\n",
    " <img src=\"images/LinearModel_1.png\"  align=\"center\"/>\n",
    " \n",
    "\n",
    "\n",
    "The linear layers in PyTorch perform a basic $xW + b$. These \"fully connected\" layers connect each input to each output with some weight parameter. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wouldn't expect a simple linear model $f(x) = xW+b$ directly outputting the class label and minimizing mean squared error to work well - the model would output labels like 3.55 and 2.11 instead of skipping to integers.\n",
    "\n",
    "Let's make two changes that make more sense for classification:\n",
    "- Change the output to be a length-10 vector of class probabilities (0 to 1, adding to 1).\n",
    "- Cross entropy as the loss function, which is typical for classification. You can read more [here](https://gombru.github.io/2018/05/23/cross_entropy_loss/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # First, we need to convert the input image to a vector by using \n",
    "        # nn.Flatten(). For MNIST, it means the second dimension 28*28 becomes 784.\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        # Here, we add a fully connected (\"dense\") layer that has 28 x 28 = 784 input nodes \n",
    "        #(one for each pixel in the input image) and 10 output nodes (for probabilities of each class).\n",
    "        self.layer_1 = nn.Linear(28*28, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = self.layer_1(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need:\n",
    "- A loss function $J(\\theta)$ where $\\theta$ is the list of parameters (here W and b). Last week, we used mean squared error (MSE), but this time we're switching to cross entropy since it's classification.  \n",
    "\n",
    "- An optimization method or optimizer such as the stochastic gradient descent (sgd) method, the Adam optimizer, RMSprop, Adagrad etc. Let's start with stochastic gradient descent (sgd), like last week. For far more information about more advanced optimizers than basic SGD, with some cool animations, see https://ruder.io/optimizing-gradient-descent/ or https://distill.pub/2017/momentum/.\n",
    "\n",
    "- A learning rate. As we learned last week, the learning rate controls how far we move during each step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = LinearClassifier()\n",
    "print(linear_model)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(linear_model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning\n",
    "Now we are ready to train our first model. A training step is comprised of:\n",
    "- A forward pass: the input is passed through the network\n",
    "- Backpropagation: A backward pass to compute the gradient $\\frac{\\partial J}{\\partial \\mathbf{W}}$ of the loss function with respect to the parameters of the network.\n",
    "- Weight updates $\\mathbf{W} = \\mathbf{W} - \\alpha \\frac{\\partial J}{\\partial \\mathbf{W}} $ where $\\alpha$ is the learning rate.\n",
    "\n",
    "How many steps do we take?\n",
    "- The batch size corresponds to the number of training examples in one pass (forward + backward). A smaller batch size allows the model to learn from individual examples but takes longer to train. A larger batch size requires fewer steps but may result in the model not capturing the nuances in the data. The higher the batch size, the more memory you will require.  \n",
    "- An epoch means one pass through the whole training data (looping over the batches). Using few epochs can lead to underfitting and using too many can lead to overfitting.\n",
    "- The choice of batch size and learning rate are important for performance, generalization and accuracy in deep learning.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(dataloader, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # forward pass\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        # backward pass calculates gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # take one step with these gradients\n",
    "        optimizer.step()\n",
    "        \n",
    "        # resets the gradients \n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode - some NN pieces behave differently during training\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    loss, correct = 0, 0\n",
    "\n",
    "    # We can save computation and memory by not calculating gradients here - we aren't optimizing \n",
    "    with torch.no_grad():\n",
    "        # loop over all of the batches\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            loss += loss_fn(pred, y).item()\n",
    "            # how many are correct in this batch? Tracking for accuracy \n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    loss /= num_batches\n",
    "    correct /= size\n",
    "    \n",
    "    accuracy = 100*correct\n",
    "    return accuracy, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "epochs = 5\n",
    "for j in range(epochs):\n",
    "    train_one_epoch(train_dataloader, linear_model, loss_fn, optimizer)\n",
    "    \n",
    "    # checking on the training loss and accuracy once per epoch\n",
    "    acc, loss = evaluate(train_dataloader, linear_model, loss_fn)\n",
    "    print(f\"Epoch {j}: training loss: {loss}, accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize how the model is doing on the first 10 examples\n",
    "pltsize=1\n",
    "plt.figure(figsize=(10*pltsize, pltsize))\n",
    "linear_model.eval()\n",
    "batch = next(iter(train_dataloader))\n",
    "predictions = linear_model(batch[0])\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(1,10,i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(batch[0][i,0,:,:], cmap=\"gray\")\n",
    "    plt.title('%d' % predictions[i,:].argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: How can you improve the accuracy? Some things you might consider: increasing the number of epochs, changing the learning rate, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "\n",
    "For a better measure of the quality of the model, let's see the model accuracy for the validation data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_val, loss_val = evaluate(val_dataloader, linear_model, loss_fn)\n",
    "print(\"Validation loss: %.4f, validation accuracy: %.2f%%\" % (loss_val, acc_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now take a closer look at the results.\n",
    "\n",
    "Let's define a helper function to show the failure cases of our classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_failures(model, dataloader, maxtoshow=10):\n",
    "    model.eval()\n",
    "    batch = next(iter(dataloader))\n",
    "    predictions = model(batch[0])\n",
    "    \n",
    "    rounded = predictions.argmax(1)\n",
    "    errors = rounded!=batch[1]\n",
    "    print('Showing max', maxtoshow, 'first failures. '\n",
    "          'The predicted class is shown first and the correct class in parentheses.')\n",
    "    ii = 0\n",
    "    plt.figure(figsize=(maxtoshow, 1))\n",
    "    for i in range(batch[0].shape[0]):\n",
    "        if ii>=maxtoshow:\n",
    "            break\n",
    "        if errors[i]:\n",
    "            plt.subplot(1, maxtoshow, ii+1)\n",
    "            plt.axis('off')\n",
    "            plt.imshow(batch[0][i,0,:,:], cmap=\"gray\")\n",
    "            plt.title(\"%d (%d)\" % (rounded[i], batch[1][i]))\n",
    "            ii = ii + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the first 10 images from the validation data that this small model classified to a wrong class:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_failures(linear_model, val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # Exercise:\n",
    "- Try changing the loss function,\n",
    "- Try changing the optimizer -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Model\n",
    "Our linear model isn't enough for high accuracy on this dataset. To improve the model, we often need to add more layers and nonlinearities.\n",
    "<img src=\"images/shallow_nn.png\"  align=\"left\"/>\n",
    "\n",
    "The output of this NN can be written as\n",
    "\\begin{equation}\\label{eq: NN1d}\n",
    "  \\hat{u}(x) = \\sigma_2(\\sigma_1(\\mathbf{x}\\mathbf{W}_1 + \\mathbf{b}_1)\\mathbf{W}_2 + \\mathbf{b}_2),\n",
    "\\end{equation}\n",
    "where $\\mathbf{x}$ is the input, $\\mathbf{W}_j$ are the weights of the neural network, $\\sigma_j$ the (nonlinear) activation functions, and $\\mathbf{b}_j$ its biases. The activation function introduces the nonlinearity and makes it possible to learn more complex tasks. Desirable properties in an activation function include being differentiable, bounded, and monotonic.\n",
    "\n",
    "\n",
    "Image source: [PragatiBaheti](https://www.v7labs.com/blog/neural-networks-activation-functions)\n",
    "<img src=\"images/activation.jpeg\"  align=\"center\"/>\n",
    "\n",
    "Adding more layers to obtain a deep neural network:\n",
    "<img src=\"images/deep_nn.png\"  align=\"left\"/>\n",
    "\n",
    "\n",
    "\n",
    "# Important things to know\n",
    "Deep Neural networks can be overly flexible/complicated and \"overfit\" your data, just like fitting overly complicated polynomials:\n",
    "<img src=\"images/bias_vs_variance.png\"  align=\"left\"/>\n",
    "\n",
    "To improve the generalization of our model on previously unseen data, we employ a technique known as regularization, which constrains our optimization problem in order to discourage complex models.\n",
    "\n",
    "  - Dropout is the commonly used regularization technique. The Dropout layer randomly sets input units to 0 with a frequency of rate at each step during training time, which helps prevent overfitting.\n",
    "  - Penalizing the loss function by adding a term such as $\\lambda ||\\mathbf{W}||^2$ is alsp a commonly used regularization technique. This helps \"control\" the magnitude of the weights of the network.\n",
    "    \n",
    "<!--  <img src=\"images/test_data_rule.png\" width=\"800\" hight=\"500\" align=\"center\"/>\n",
    "  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now implement a deep network in PyTorch. nn.Dropout() performs the Dropout operation mentioned earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NonlinearClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.layers_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 50),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(0.2),\n",
    "            nn.Linear(50, 50),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(0.2),\n",
    "            nn.Linear(50, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.layers_stack(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework: train a Nonlinear Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write some code to train the NonlinearClassifier.\n",
    "2. Create a data loader for the test data and check your model's accuracy on the test data. \n",
    "\n",
    "If you have time, experiment with how to improve the model. Note: training and validation data can be used to compare models, but test data should be saved until the end as a final check of generalization. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JupyterHub Reminder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From [Homework 0](https://github.com/argonne-lcf/ai-science-training-series/blob/main/00_introToAlcf/02_jupyterNotebooks.md): \"If you simply close your browser window, or logout without shutting down the jupyter server, your job will continue to occupy the worker node. Be considerate and shutdown your job when you finish.\"\n",
    "\n",
    "File --> Hub Control Panel --> Stop my server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(TorchANI)",
   "language": "python",
   "name": "torchani"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
